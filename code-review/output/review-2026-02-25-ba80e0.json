{
  "filtered_findings": [
    {
      "id": "ASD-001-SEC-002",
      "file": "lib/store.py",
      "line_start": 250,
      "line_end": 275,
      "severity": "critical",
      "confidence": 0.90,
      "category": "race_condition",
      "source_agent": "async-data-integrity + security-sentinel",
      "title": "archive_session verplaatst bestand zonder session lock — TOCTOU en race condition",
      "body": "archive_session leest de JSON, controleert de status en roept shutil.move aan volledig buiten _session_lock. Alle andere schrijfpaden (heartbeat, update_session, add_event) gebruiken _session_lock en _atomic_write (write-to-tempfile + os.rename). Concreet scenario: Thread A (heartbeat op sessie S) acquireert de lock en schrijft updated data via atomic rename naar sess_X.json. Tegelijkertijd roept Thread B (archive_session op S) de status als COMPLETED, en doet shutil.move. Als Thread A's rename plaatsvindt na Thread B's read maar voor de shutil.move, verplaatst Thread B het net-bijgewerkte bestand. Resultaat: de heartbeat-update verdwijnt stilletjes in het archief, of shutil.move racet met os.rename waardoor de sessies-directory inconsistent is. Aanvullend: een corrupt JSON-bestand met session_id='../../config.json' gooit een ValueError in archive_session die in archive_old_sessions niet wordt gecatch, waardoor de resterende sessies niet worden verwerkt. Fix: wikkel de volledige body van archive_session (read + status check + move + lock cleanup) in een with _session_lock(session_id): blok.",
      "suggestion": "def archive_session(session_id: str) -> bool:\n    _validate_session_id(session_id)\n    _ensure_dirs()\n    with _session_lock(session_id):\n        src = SESSIONS_DIR / f\"{session_id}.json\"\n        if not src.exists():\n            return False\n        with open(src) as f:\n            data = json.load(f)\n        if data.get(\"status\") != SessionStatus.COMPLETED:\n            return False\n        dst = ARCHIVE_DIR / f\"{session_id}.json\"\n        shutil.move(str(src), str(dst))\n        lock = SESSIONS_DIR / f\"{session_id}.lock\"\n        lock.unlink(missing_ok=True)\n    return True",
      "requires_human_review": true,
      "filter_score": 10,
      "filter_rationale": "Concreet exploiteerbaar race condition met aantoonbaar dataverlies; beide agents signaleren hetzelfde patroon; directe crash van archiveerjob via exception zonder catch",
      "solution_ref": "SOL-2026-004",
      "resolved": false
    },
    {
      "id": "ASD-002",
      "file": "lib/store.py",
      "line_start": 493,
      "line_end": 542,
      "severity": "high",
      "confidence": 0.85,
      "category": "data_integrity",
      "source_agent": "async-data-integrity",
      "title": "resume_session laat oude sessie achter in inconsistente COMPLETED-staat bij crash",
      "body": "De gerefactorde resume_session verdeelt de update van de oude sessie over twee aparte lock-blokken. In lock-blok 1 (rond regel 496-506): old.status wordt COMPLETED, old.ended_at wordt gezet, _save_session schrijft naar disk, en de lock wordt losgelaten. Het outcome-veld ('Resumed as <new_id>') wordt pas geschreven in lock-blok 3 (na create_session en een tweede lock-blok op de nieuwe sessie). Bij een crash (OOM kill, SIGKILL, stroomuitval) na lock-blok 1 maar voor lock-blok 3 wordt de oude sessie permanent opgeslagen als status=COMPLETED met ended_at maar outcome=None. Gebruikers en de overview API zien een completed sessie zonder verklaring. De sessie kan niet meer worden hervat (al COMPLETED). Dit is een observeerbare, niet-herstelbare inconsistentie.",
      "suggestion": "# In het eerste _session_lock(session_id) blok, sla een placeholder outcome op:\nold.status = SessionStatus.COMPLETED\nold.ended_at = _now_iso()\nold.outcome = \"Resuming...\"  # wordt overschreven in lock-blok 3\n_save_session(old)\n# ... dan in lock-blok 3 overschrijven met het echte outcome.",
      "requires_human_review": true,
      "filter_score": 10,
      "filter_rationale": "Observeerbare, niet-herstelbare data-inconsistentie bij crash; concreet scenario met SIGKILL; nieuwe code in deze PR; directe impact op gebruikersdata",
      "solution_ref": "SOL-2026-015",
      "resolved": false
    },
    {
      "id": "LOG-001",
      "file": "lib/store.py",
      "line_start": 178,
      "line_end": 180,
      "severity": "high",
      "confidence": 0.90,
      "category": "null_reference",
      "source_agent": "logic-correctness",
      "title": "fresh_new wordt gebruikt zonder None-check na get_session in resume_session",
      "body": "In de nieuwe resume_session-implementatie wordt na het aanmaken van een nieuwe sessie de sessie opnieuw gelezen via get_session(new_session.session_id) en direct gebruikt: fresh_new.open_questions = open_questions. get_session kan echter None teruggeven — bijvoorbeeld als een ander proces de sessie verwijdert tussen create_session en de lock-acquisitie (cleanup_orphaned_locks, cleanup_stale, of handmatige delete). In dat geval crasht de code met AttributeError: 'NoneType' object has no attribute 'open_questions'.",
      "suggestion": "fresh_new = get_session(new_session.session_id)\nif fresh_new is None:\n    raise RuntimeError(f\"Session {new_session.session_id} vanished after creation\")\nfresh_new.open_questions = open_questions\n_save_session(fresh_new)",
      "requires_human_review": true,
      "filter_score": 10,
      "filter_rationale": "Concrete crash (AttributeError) bij plausibel concurrent scenario; nieuwe code in deze PR; fix is triviaal en duidelijk",
      "solution_ref": "SOL-2026-015",
      "resolved": false
    },
    {
      "id": "LOG-002",
      "file": "lib/store.py",
      "line_start": 304,
      "line_end": 309,
      "severity": "high",
      "confidence": 0.85,
      "category": "type_mismatch",
      "source_agent": "logic-correctness",
      "title": "Naive vs aware datetime-vergelijking crasht in archive_old_sessions",
      "body": "archive_old_sessions vergelijkt ended (geparseerd met datetime.fromisoformat(ended_at)) met cutoff = datetime.now(UTC). Als ended_at is opgeslagen zonder timezone-offset (bijv. '2025-12-01T10:00:00' in plaats van '2025-12-01T10:00:00+00:00'), geeft fromisoformat een timezone-naive datetime terug. De vergelijking ended < cutoff gooit dan een TypeError: can't compare offset-naive and offset-aware datetimes. De except ValueError vangt TypeError niet op, dus de functie crasht. Concreet bij sessies aangemaakt door een oudere versie van de store of handmatig bewerkte JSON.",
      "suggestion": "ended = datetime.fromisoformat(ended_at)\nif ended.tzinfo is None:\n    ended = ended.replace(tzinfo=UTC)\nif ended < cutoff:",
      "requires_human_review": true,
      "filter_score": 10,
      "filter_rationale": "TypeError crasht de archiveerfunctie op bestaande v1-data; concreet scenario met legacy sessiebestanden; nieuwe code in deze PR; one-liner fix",
      "solution_ref": null,
      "resolved": false
    },
    {
      "id": "PYT-001",
      "file": "lib/store.py",
      "line_start": 226,
      "line_end": 229,
      "severity": "high",
      "confidence": 0.90,
      "category": "service_layer",
      "source_agent": "python-specialist",
      "title": "list_sessions roept _session_from_dict aan zonder schema-migratie",
      "body": "In list_sessions wordt data direct aan _session_from_dict doorgegeven zonder eerst _migrate_session_data aan te roepen. get_session en get_archived_session doen dit wel. Een legacy v1-sessie op disk heeft geen 'tasks' veld. Als _session_from_dict dat veld vereist (of als downstream code s.tasks aanroept), geeft dit een KeyError of AttributeError bij het listen van sessies. Dit is een inconsistentie die pas zichtbaar wordt op een installatie met bestaande v1-data — precies het scenario waarvoor schema-migratie (C1) bedoeld is.",
      "suggestion": "Vervang in de list_sessions loop:\n    session = _session_from_dict(data)\ndoor:\n    data = _migrate_session_data(data)\n    session = _session_from_dict(data)",
      "requires_human_review": true,
      "filter_score": 10,
      "filter_rationale": "Ondermijnt de schema-migratie die expliciet in deze PR wordt geïntroduceerd; concrete crash bij bestaande v1-installaties; triviale one-liner fix",
      "solution_ref": null,
      "resolved": false
    },
    {
      "id": "PRF-001",
      "file": "lib/store.py",
      "line_start": 707,
      "line_end": 727,
      "severity": "high",
      "confidence": 0.95,
      "category": "unnecessary_query",
      "source_agent": "performance-reviewer",
      "title": "archive_old_sessions leest elk in aanmerking komend bestand twee keer",
      "body": "archive_old_sessions opent en parseert elk sessie-JSON-bestand in de loop om status en ended_at te inspecteren. Voor sessies die beide checks doorstaan, roept het daarna archive_session(sid) aan, die hetzelfde bestand opnieuw opent en parseert om de status te verifiëren voor de move. Bij 500+ sessies in SESSIONS_DIR verdubbelt dit de disk I/O en JSON-parse tijd voor elke te archiveren sessie.",
      "suggestion": "Vervang de archive_session(sid) aanroep in archive_old_sessions door een directe move na de al-bevestigde status/datum checks:\n\n    if ended < cutoff:\n        sid = data[\"session_id\"]\n        dst = ARCHIVE_DIR / f\"{sid}.json\"\n        shutil.move(str(path), str(dst))\n        lock = SESSIONS_DIR / f\"{sid}.lock\"\n        lock.unlink(missing_ok=True)\n        archived.append(sid)\n        affected_projects.add(data.get(\"project_slug\", \"\"))\n\nOf extraheer een _move_to_archive(path, data) helper die zowel archive_session als archive_old_sessions aanroepen.",
      "requires_human_review": true,
      "filter_score": 10,
      "filter_rationale": "Meetbare dubbele disk I/O bij schaalbare archief; concrete impact bij realistisch gebruik na maanden; hoge confidence; fix is actionable",
      "solution_ref": null,
      "resolved": false
    },
    {
      "id": "SEC-001",
      "file": "lib/store.py",
      "line_start": 250,
      "line_end": 275,
      "severity": "medium",
      "confidence": 0.82,
      "category": "path_traversal",
      "source_agent": "security-sentinel",
      "title": "archive_old_sessions catchet ValueError van _validate_session_id niet",
      "body": "In archive_old_sessions wordt sid = data['session_id'] direct uit de JSON-inhoud van een sessiebestand gehaald en doorgegeven aan archive_session. archive_session roept _validate_session_id aan, die een ValueError gooit bij een ongeldige session_id (bijv. '../../config.json' in een corrupt of kwaadaardig bestand). Die ValueError wordt in archive_old_sessions niet gecatch. Resultaat: de archiveringsjob crasht bij het eerste corrupte bestand en verwerkt de resterende sessies niet.",
      "suggestion": "try:\n    if archive_session(sid):\n        archived.append(sid)\n        affected_projects.add(data.get(\"project_slug\", \"\"))\nexcept ValueError:\n    logger.warning(\"Skipping session with invalid ID in file %s\", path)",
      "requires_human_review": false,
      "filter_score": 9,
      "filter_rationale": "Concrete crash van de archiveerjob bij corrupt JSON; eenvoudige defensive fix; deels afgedekt door ASD-001-SEC-002 maar het exception-handling aspect is apart actionable",
      "solution_ref": "SOL-2026-004",
      "resolved": false
    }
  ],
  "filter_stats": {
    "received": 21,
    "hard_excluded": 3,
    "duplicates_merged": 2,
    "confidence_filtered": 3,
    "score_filtered": 5,
    "max_capped": 1,
    "final_count": 7
  },
  "verdict": "changes_requested",
  "verdict_rationale": "1 CRITICAL en 5 HIGH bevindingen vereisen aanpassing voor merge: race condition in archive_session (dataverlies), inconsistente sessie-staat bij crash in resume_session, None-crash in resume_session, datetime-vergelijkingscrash in archive_old_sessions, ontbrekende schema-migratie in list_sessions, en dubbele disk I/O in archive_old_sessions",
  "risk_score": 100
}
